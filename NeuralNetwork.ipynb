{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35973e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb30decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply oop\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, activation_dims):\n",
    "        \n",
    "        self.activation_dims = activation_dims\n",
    "        self.layers = len(activation_dims)\n",
    "        self.network = {}\n",
    "        self.gradient = {}\n",
    "        \n",
    "        self.create_network()\n",
    "        \n",
    "    def create_network(self):\n",
    "        \n",
    "        for layer in range(self.layers):\n",
    "            self.network[layer+1] = {}\n",
    "            \n",
    "            if (layer+1 == 1):\n",
    "  \n",
    "                self.network[layer+1][\"activations\"] = self.sigmoid(np.empty(self.activation_dims[layer]).reshape(-1,1)) \n",
    "                \n",
    "            else:\n",
    "                self.network[layer+1][\"activations\"] = np.random.rand(self.activation_dims[layer]).reshape(-1,1)\n",
    "                self.network[layer+1][\"weights\"] = np.random.uniform(-0.5, 0.5, size = self.activation_dims[layer]*self.activation_dims[layer-1]).reshape(self.activation_dims[layer], self.activation_dims[layer-1])\n",
    "                self.network[layer+1][\"biases\"] = np.random.uniform(-0.5, 0.5, size = self.activation_dims[layer]).reshape(-1,1)\n",
    "    \n",
    "    def create_gradient(self):\n",
    "        \n",
    "        g = {}\n",
    "        for layer in range(2, self.layers+1):\n",
    "            g[layer] = {}\n",
    "            \n",
    "            g[layer][\"weights\"] = np.zeros(self.network[layer][\"weights\"].shape)\n",
    "            g[layer][\"biases\"] = np.zeros(self.network[layer][\"biases\"].shape)\n",
    "\n",
    "        return g\n",
    "       \n",
    "    def calculate_z(self, a, w, b):\n",
    "\n",
    "        \"\"\"caculate z from z = a*w + b\"\"\"\n",
    "\n",
    "        return np.dot(w, a) + b\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "    \n",
    "        \"\"\"return value of sigmoid function of x\"\"\"\n",
    "\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def cost_function_derivative(self, a, y):\n",
    "        \n",
    "        \"\"\"return value of the cost function derivative of a and y\"\"\"\n",
    "\n",
    "        return 2*(a-y)\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \n",
    "        \"\"\"reuturn value of sigmoid derivative of x\"\"\"\n",
    "\n",
    "        return (1/(1+np.exp(-x))**2)*np.exp(-x)\n",
    "\n",
    "    def forward(self, data, index):\n",
    "        \n",
    "        \"\"\"calculate activations in each layer\"\"\"\n",
    "        \n",
    "        for layer in range(1, self.layers+1):\n",
    "            \n",
    "            if (layer == 1):\n",
    "  \n",
    "                # self.network[layer][\"activations\"] = self.sigmoid(data[index].reshape(-1,1))\n",
    "                self.network[layer][\"activations\"] = (data[index].reshape(-1,1))/255\n",
    "                \n",
    "            else:\n",
    "    \n",
    "                self.network[layer][\"activations\"] = self.sigmoid(self.calculate_z(self.network[layer-1][\"activations\"], self.network[layer][\"weights\"], self.network[layer][\"biases\"]))\n",
    "            \n",
    "        \n",
    "    def back(self, l, g, e = None):\n",
    "\n",
    "        \"\"\"compute backpropagation and return gradient of the network\"\"\"\n",
    "        \n",
    "        n = self.network\n",
    "        \n",
    "        if (l == 1):\n",
    "            return g\n",
    "        else:\n",
    "            z = self.calculate_z(n[l-1][\"activations\"], n[l][\"weights\"], n[l][\"biases\"])\n",
    "            da_by_dz = self.sigmoid_derivative(z)\n",
    "\n",
    "            if (l == len(n)):\n",
    "                dc_by_da = self.cost_function_derivative(n[l][\"activations\"], e)\n",
    "            else:\n",
    "                dc_by_da = np.sum(g[l+1][\"biases\"]*n[l+1][\"weights\"], axis = 0).reshape(-1,1)\n",
    "                # dc_by_da = np.dot(n[l+1][\"weights\"], g[l+1[\"biases\"]])\n",
    "\n",
    "            g[l][\"weights\"] = n[l-1][\"activations\"].reshape(-1)*dc_by_da*da_by_dz\n",
    "            g[l][\"biases\"] = dc_by_da*da_by_dz\n",
    "            g = self.back(l-1,g)\n",
    "            return g\n",
    "\n",
    "    \n",
    "    def add_gradient(self, g1, g2):\n",
    "\n",
    "        \"\"\"return added gradient\"\"\"\n",
    "\n",
    "        w = \"weights\"\n",
    "        b = \"biases\"\n",
    "        l = len(g1)\n",
    "        \n",
    "        for i in range(2, l+2, 1):\n",
    "            g1[i][w] += g2[i][w]\n",
    "            g1[i][b] += g2[i][b]\n",
    "\n",
    "        return g1\n",
    "\n",
    "    def average_gradient(self, g, batch_size):\n",
    "\n",
    "        \"\"\"averaging the gradient with batch size and return averaged gradient\"\"\"\n",
    "\n",
    "        w = \"weights\"\n",
    "        b = \"biases\"\n",
    "        for i in range(2, self.layers + 1, 1):\n",
    "            g[i][w]/=batch_size\n",
    "            g[i][b]/=batch_size\n",
    "\n",
    "        return g\n",
    "\n",
    "    def graident_descent(self, g, lr):\n",
    "\n",
    "        \"\"\"compute graident descent\"\"\"\n",
    "        \n",
    "        w = \"weights\"\n",
    "        b = \"biases\"\n",
    "        for i in range(2, self.layers + 1, 1):\n",
    "            self.network[i][w] -= lr*g[i][w]\n",
    "            self.network[i][b] -= lr*g[i][b]\n",
    "            \n",
    "    \n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    def test():\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e30300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation dimensions : [784, 32, 16, 10]\n",
      "learning rate : 0.02\n",
      "epochs : 3\n",
      "batch_size : 10\n",
      "accuracy 1 : 30.930000000000003 %\n",
      "accuracy 2 : 55.25 %\n",
      "accuracy 3 : 72.63 %\n"
     ]
    }
   ],
   "source": [
    "n = NeuralNetwork([784, 32, 16, 10])\n",
    "\n",
    "learning_rate = 0.02\n",
    "epochs = 3\n",
    "batch_size = 10\n",
    "\n",
    "print(\"activation dimensions :\", n.activation_dims)\n",
    "print(\"learning rate :\", learning_rate)\n",
    "print(\"epochs :\", epochs)\n",
    "print(\"batch_size :\", batch_size)\n",
    "\n",
    "for i in range(epochs):\n",
    "    index = 0\n",
    "    for j in range(0, 60000, batch_size):\n",
    "        \n",
    "        n.gradient = n.create_gradient()\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            \n",
    "            n.forward(x_train, index)\n",
    "            expect_num = y_train[index]\n",
    "            expect_output = np.zeros(10)\n",
    "            expect_output[expect_num] = 1\n",
    "            expect_output = expect_output.reshape((-1,1))\n",
    "            n.gradient = n.add_gradient(n.gradient, n.back(l = n.layers, g = n.create_gradient(), e = expect_output))\n",
    "            index += 1  \n",
    "        \n",
    "        n.gradient = n.average_gradient(n.gradient, batch_size)\n",
    "        n.graident_descent(n.gradient, learning_rate)\n",
    "\n",
    "    index = 0\n",
    "    correct = 0\n",
    "    for j in range(10000):\n",
    "        n.forward(x_test, index)\n",
    "        expect_num = y_test[index]\n",
    "        \n",
    "        output = n.network[n.layers][\"activations\"]\n",
    "        if(np.argmax(output) == expect_num):\n",
    "            correct += 1\n",
    "        index += 1\n",
    "        \n",
    "    print(\"accuracy\", i + 1, \":\", (correct/index)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
